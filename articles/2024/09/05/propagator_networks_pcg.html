<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">
    <title>
        Propagator networks
    </title>
    <link rel="stylesheet" type="text/css" href="/static/style/article.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Taviraj&family=Work+Sans&display=swap" rel="stylesheet">
    <link href="https://pvinis.github.io/iosevka-webfont/3.4.1/iosevka.css" rel="stylesheet" />

    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/base16/gigavolt.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/haskell.min.js"></script>


    <script type="text/javascript">
        hljs.highlightAll();
    </script>
</head>

<body>
    <div class="bg-image"></div>
    <div id="page-wrapper">
        <div id="banner">
            <a href="/">
                <svg class="arrow">
                    <image href="/static/img/templates/arrow_neg.svg" />
                </svg>
                <span>home</span>
            </a>
        </div>
        <div id="article-body">
            <div id="date">
                Sep 5, 2024
            </div>
            <div id="article-title">
                Propagator networks
            </div>
            <p>A little while ago I came across <a href="https://www.youtube.com/watch?v=s2dknG7KryQ" title="">this video</a> of Ed Kmett talking about something called propagators.  From there I found <a href="https://dspace.mit.edu/bitstream/handle/1721.1/44215/MIT-CSAIL-TR-2009-002.pdf" title="">the paper that originally introduced these things</a>, co-written by Alexey Radul and the venerable Gerald Sussman (which I would highly recommend checking out).  Radul&#39;s <a href="https://dspace.mit.edu/bitstream/handle/1721.1/54635/603543210-MIT.pdf" title="">PhD dissertation from the same year</a> is effectively a more thorough and unabridged version of the paper, and also worth reading through if you, like me, become seduced into implementing these yourself.</p><p><img src="res/propagators.png" title=""></p><h1>Propagator networks?</h1><p>I think the best way to describe propagator networks (or <em>propagation</em> networks — both get used interchangeably) is that they are a model for building computations, somewhere between a design pattern and a programming paradigm. The standard approach to computing has us build a program as a sequential evaluation of expressions, each of which transforms our data or produces some side effects. This obviously works pretty well, but it encourages us to approach problem-solving as a kind of one-way mapping from a known input to an unknown output, and we sometimes have problems that don&#39;t fit nicely into this frame.  Instead of having one thing that transforms into another, what if we have a bunch of things that &quot;non-linearly&quot; relate or react to one another?</p><p>Propagation networks are really great at expressing this latter type of problem. Networks are made up of a bunch of &quot;cells&quot; which accumulate information <em>about</em> a value (I know that&#39;s a bit abstract, but bear with me here) and we interconnect these cells with reactive functions called <em>propagators</em>. Propagators link some input cells to some output cells, and when any of the inputs are updated with new information, the propagator pulls in all of the inputs, processes that information in some way and propagates the result to all of the outputs.</p><p>This architecture turns out to be pretty flexible and opens up a new kind of expressive power for us. By modelling the flow of information as a graph rather than a sequence or tree, we relax the linear structure of time in our approach to solving a problem.  We simply implement relationships or connections between values, and the order in which they are evaluated is determined at runtime.</p><p>However, we now have some new pitfalls to avoid. Unless cells have a way to determine whether incoming information is &quot;new&quot; or not, our network will just keep propagating stuff around forever. And since we would probably like our programs to terminate, we need to carefully define decide how to represent this information, and what it means for cells to &quot;accumulate&quot; it.</p><h2>Time for some math</h2><p>Before we come up with a concrete implementation for our &quot;partial information&quot;, we need to decide what kind of laws it should follow. When a cell gets some new information, we intuitively expect the result to be a logical combination of the information coming in and the information that was already in the cell. And if the incoming information isn&#39;t just redundant, we want that combination to be &quot;greater than&quot; either of the inputs on their own, in the sense that it holds more information.</p><p>Whenever we need a way to talk about a class of things that follow some abstract rules, it&#39;s a safe bet that mathematicians already have an entire field dedicated to what we&#39;re looking for. And, lo and behold, this is the case for us here. A set where we can compare elements using the <code>&lt;=</code> relation is called a <a href="https://en.wikipedia.org/wiki/Partially_ordered_set" title="">partial order</a>. And better yet, there&#39;s a special type of partial order called a <a href="https://en.wikipedia.org/wiki/Semilattice" title="">semilattice</a> which includes an operation we can use to combine elements.</p><p>Before I start throwing more jargon around let&#39;s get a little example going. Say we have a network where we want each cell to settle on one of three values: <code>A</code>, <code>B</code>, or <code>C</code>. The information inside a cell in this case is simple: at any point in time, a cell stores the set of values it <em>could</em> be. We&#39;ll initialize the cells with the universal set <code>{A,B,C}</code> and the idea is that some of these elements will get discarded over time until we&#39;re down to a singleton, which we can interpret as the final value for the cell. There&#39;s a neat little thing called a <a href="https://en.wikipedia.org/wiki/Hasse_diagram" title="">Hasse diagram</a> which lets us visually represent partial orders.  Let&#39;s make one for the information in our cells.</p><p><img src="res/hasse.png" title=""></p><p>The arrows between elements in the Hasse diagram indicate the ordering between elements. We can say that <code>x &lt;= y</code> if there is a direct path from <code>x</code> to <code>y</code> in the diagram (or they are the same). Note that it doesn&#39;t really make sense to ask whether <code>{A, B}</code> or <code>{A, C}</code> is &quot;greater&quot; than the other, which is why our information is a <em>partial order</em> not a <em>total order</em>! You should be able to see how the elements contain more information (or less entropy, if that makes more sense to you) as we move up the graph.</p><p>The semilattice operation I mentioned that let&#39;s us combine elements is called &quot;join&quot; (since we are specifically dealing with join-semilattices; there&#39;s a dual operation called &quot;meet&quot; for, you guessed it, meet-semilattices). What join actually does is gives us the &quot;least upper bound&quot; for two elements of the semilattice, which is the least element that is greater than both of the operands.  For example, the least upper bound of <code>{A,B}</code> and <code>{B,C}</code> in the diagram above is <code>{C}</code> so <code>{A,B} ∧ {B,C} == {C}</code>.</p><p>You might have noticed by now that the top of the Hasse diagram has an empty set element <code>{}</code>, which doesn&#39;t really correspond to a value.  In practice, if our cell holds the empty set, it means there are no possible values that the cell could be, and that our problem is unsolvable! In other words, moving above the row of singletons means that we&#39;ve encountered some kind of contradiction, in which case we immediately stop propagating and indicate that our computation has failed.</p><p>Ok that was a lot of explaining, but now we get to actually put all of this into practice!</p><h1>Constraint satisfaction problems</h1><p>Radul picks out a few different subdisciplines which all share a kind of non-linear approach to computing, and thus generalize very nicely to propagation networks, but the one I&#39;m the most drawn to at the moment is constraint satisfaction problems.</p><p>In a CSP, you have a bunch of variables and some rules for how those variables relate to each other (called constraints), and the goal is to assign a value to each variable such that all of your constraints are satisfied. This obviously maps super nicely onto propagator networks.  We&#39;ll create a cell for each variable, which will store information about what the variable could be (i.e. a set of possible values).  Between these cells we install propagators which enforce the relations by translating between sets of possibilities.  Each cell is then able to refine its possibility-space by taking the intersection of the incoming sets, ideally culminating in a single value.</p><h2>Vertex coloring</h2><p>Let&#39;s look at a nice simple CSP and how we would solve it with a propagator network. A sudoku puzzle is the typical example of a CSP that most people are familiar with. But I want to draw everything out visually, and with a sudoku puzzle there are just so many nodes and connections that it becomes kind of a mess to look at, so instead I&#39;m going to walk through an example using <a href="https://en.wikipedia.org/wiki/Graph_coloring" title="">vertex coloring</a> (sudoku is actually a specific case of vertex coloring using 9 &quot;colors&quot; on a big graph with 81 vertices and 810 edges).</p><p>We&#39;ll be finding a 3-coloring of a Petersen graph, which looks like this:</p><p><img src="res/vertcolor-00.png" title=""></p><p>And here is the code that will solve our constraint problem:</p><pre><code class="language-haskell">data Color = Red | Green | Blue deriving (Bounded, Enum)

edges :: [a] -&gt; [(a, a)]
edges xs =
  let outside = take 5 xs
      inside = drop 5 xs
   in zip outside (drop 1 (cycle outside)) 
        ++ zip inside (drop 2 (cycle inside)) 
        ++ zip outside inside

vertexColors :: PropNetIO (Maybe [Color])
vertexColors = do
  cells &lt;- replicateM 10 empty
  for_ (edges cells) (enforceBinary neqR)
  search cells
</code></pre><p>There&#39;s some additional parts which run the network and render the colored graph, but those aren&#39;t important right now. You can check out the <a href="https://github.com/jehoz/propnet/blob/master/examples/VertexColor.hs" title="">example on Github</a> if you want to see the full working code.</p><p>We define a <code>Color</code> type with our three possible colors (the <code>Bounded</code> and <code>Enum</code> instances are necessary to use this type as a set of possibilities). The <code>edges</code> function just takes a list of 10 elements and returns those elements in pairs corresponding to each of the edges in the Petersen graph.</p><p>The <code>vertexColors</code> function is where the magic is happening, and as you can see it&#39;s pretty simple. The type signature says that we have a propagation network built on top of the <code>IO</code> monad (<code>PropNetST</code> is also provided for building and running networks in a pure context) which will produce a singular <code>Color</code> for each vertex or <code>Nothing</code> if no solution was found.</p><p>To implement this, we first we create 10 empty cells which represent the vertices of our graph. The value inside each of these cells is of type <code>OneOf Color</code>, which is our &quot;possibility set&quot; type and implements all of the join-semilattice behavior we talked about above.  Then, for each connected pair of vertices, we enforce a binary relation <code>neqR</code> (pardon the clunky naming) which says that those two cells may not contain the same value. Behind the scenes, relations are just propagators whose input and output cells are the same, so that the same rule is enforced in all directions.</p><p>Then, we <code>search</code> for a solution.  A solution in this case being a value for each cell which satisfies the relations we enforced.  I neglected to mention the &quot;searching&quot; part of solving CSPs up until now so let&#39;s take a minute to talk about how that works.</p><h2>Guessing and backtracking</h2><p>Only the most trivial CSPs can be solved through propagation alone. What makes CSPs notoriously difficult to solve is that you typically have to search through many combinations of values for all of your variables until you find a good one, and that search space explodes in scale as the problem becomes more complex.</p><p>Since we are only dealing with discrete finite domains, we can imagine a search tree for our CSP where each undetermined variable creates a branching point such that each branch is one of the possible values we could assign to it. When we traverse down one of these branches, we are making a guess about the value of this variable, and we propagate this guess to the rest of the network to see if it&#39;s valid.  Sometimes after we propagate a guess, we discover a contradiction, and when that happens we have to backtrack and try another branch instead.</p><p>State-of-the-art <a href="https://en.wikipedia.org/wiki/SAT_solver" title="">SAT solvers</a> use all sorts of sophisticated techniques for making logical inferences throughout the search process so that the program learns to avoid certain combinations of values which lead to contradictions. In my initial implementation of this library, I was doing something similar.  Following Radul and Sussman, I built a truth maintenance system for cells which could simultaneously hold many different &quot;beliefs&quot; about the cell&#39;s value, each dependent on certain combinations of guesses.  When one cell propagated information to another, the TMSs would automatically merge the corresponding beliefs, take note of contradictions, and perform some basic <a href="https://en.wikipedia.org/wiki/Conflict-driven_clause_learning" title="">CDCL</a>.</p><p>The problem with this was that it ended up being extremely slow as it got deeper into the search tree, which kind of defeats the point I think.  I ended up switching to a basic depth-first search which saves the state of all the cells before every branch point and resets them as needed, no clever logical induction or anything, and it honestly works like a charm.  Maybe there was something wrong with my TMS implementation, or maybe you really start reaping the benefits with complex and highly-constrained CSPs, but for now it just seems like a neat idea that doesn&#39;t help that much.</p><p>Ok, that&#39;s enough coping from me.  Let&#39;s get back to the example.</p><h2>Back to the example</h2><p>In the first step you can see that there is nothing to propagate, so we just pick any vertex and give it a random color.  No starting point is really better than any other here.</p><p><img src="res/vertcolor-01.png" title=""></p><p>We always pick the next branch point by finding a cell with the fewest number of remaining possibilities.  Clearly this would be any of the vertices connected to the red one, since we can factor red out of their possibility sets. We randomly pick one to branch on and color it blue, and then we do the same for another one.</p><p><img src="res/vertcolor-02.png" title=""> <img src="res/vertcolor-03.png" title=""></p><p>Now as soon as we branch on one of the two remaining vertices of the star in the middle, we will immediately know the other one as it will only have a single possibility left.</p><p><img src="res/vertcolor-04.png" title=""></p><p>And finally, as soon as we branch on any of the outside vertices, we can solve the rest by propagation alone.</p><p><img src="res/vertcolor-05.png" title=""></p><p>Cool! If you&#39;ve ever solved a sudoku puzzle this will have been extremely boring and obvious for you, but I wanted to step through an easy example before doing the next part.</p><h1>Procedural generation</h1><p>Now let&#39;s take this same concept and repurpose it slightly. If we allow for a larger set of possibilities and/or use weaker constraints, we shift from finding a unique solution to a problem into producing a random output that follows some guidelines, which you could start to call &quot;procedural content generation&quot;. Indeed there is a PCG technique that got very trendy a few years ago called <a href="https://github.com/mxgmn/WaveFunctionCollapse" title="">wave function collapse</a> (which I think is a rediscovery of an earlier technique called <a href="https://en.wikipedia.org/wiki/Model_synthesis" title="">model synthesis</a>), which is pretty much just constraint propagation with a cool new outfit on.  WFC randomly generates a composite image (or 3D model) using a limited tileset, while enforcing constraints about which tiles can be adjacent to which other tiles. This should sound pretty familiar to you, because it&#39;s not all that different from what we just did to color the graph!  Let&#39;s build out own version of this using propagators.</p><p>Simply out of laziness, I&#39;m not going to make an actual image (but you could if you wanted to).  Instead we&#39;ll take a shortcut by drawing &quot;graphics&quot; to the terminal, using these Unicode pipe characters as our tileset:</p><pre><code class="language-">═ ║ ╔ ╗ ╚ ╝ ╠ ╣ ╦ ╩ ╬
</code></pre><p>We want to fill out a big grid where each position has one of these pipe characters, or an empty space, while making sure that all of our pipes are &quot;connected&quot;. We&#39;ll need to set up constraints to enforce a rule that says: for any pair of neighboring tiles <code>(x, y)</code>, <code>x</code> should have a connection facing <code>y</code> <em>if and only if</em>  <code>y</code> has a connection facing <code>x</code>. There are a few different ways we could approach this, but I decided to create a type representing a connection on one of the four cardinal directions, so that we can encode each tile as a combination of these connections.</p><pre><code class="language-haskell">data Connection = N | S | W | E deriving (Bounded, Enum)

type Tile = Combination Connection

showTile :: Tile -&gt; String
showTile x = case C.toList x of
  [] -&gt; &quot; &quot;
  [N, S] -&gt; &quot;║&quot;
  [W, E] -&gt; &quot;═&quot;
  [N, W] -&gt; &quot;╝&quot;
  [N, E] -&gt; &quot;╚&quot;
  [S, W] -&gt; &quot;╗&quot;
  [S, E] -&gt; &quot;╔&quot;
  [N, S, W] -&gt; &quot;╣&quot;
  [N, S, E] -&gt; &quot;╠&quot;
  [N, W, E] -&gt; &quot;╩&quot;
  [S, W, E] -&gt; &quot;╦&quot;
  [N, S, W, E] -&gt; &quot;╬&quot;
  _ -&gt; &quot;?&quot;
</code></pre><p>A <code>Combination</code> is a set with some special typeclass instances that let us enumerate each unique combination of elements, meaning we can create a cell of type <code>OneOf (Combination a)</code> which converges to a specific <em>combination</em> of values, rather than just one value.</p><p>Now we have to think of how to implement our constraint.  In the previous example we used the <code>neqR</code> relation which is pretty basic and built into the library.  This time around we&#39;ll be implementing one from scratch.  But first we need to know what relations are actually doing.  Binary relations have the following type:</p><pre><code class="language-haskell">type BinaryR a b = (a, b) -&gt; (a, b)
</code></pre><p>As you can see it&#39;s just some syntactic sugar for a function from a tuple to itself.  In practice, the type variables <code>a</code> and <code>b</code> will be some partial information type like a <code>OneOf</code>, and represent the data inside two cells.  The relation is meant to simultaneously apply a function and its converse, such that when one of the two cells changes, we always know how to update the other. Let&#39;s look at the implementation of the <code>neqR</code> relation.</p><pre><code class="language-haskell">neqR :: (Bounded a, Enum a) =&gt; BinaryR (OneOf a) (OneOf a)
neqR (x, y) =
  let f old new = if OneOf.size new == 1 then OneOf.difference old new else old
   in (f x y, f y x)
</code></pre><p>Since <em>&quot;not equal&quot;</em> is a symmetric relation, we can make one helper function and apply it to both elements in the tuple.  The helper function <code>f</code> says that if the cell on the other side of the relation has a single defined value, remove that value from this cell&#39;s set of possibilities.</p><p>Now let&#39;s think about how we can design a relation that keeps all of our tiles connected. Say we have two cells that are horizontally adjacent, if the one on the left has an <code>E</code> connection, then the one on the right <em>must</em> have a <code>W</code> connection, and vice versa.  And vertically adjacent cells need to follow a similar rule. Lets make a rule that we can parameterize with the particular <code>Connection</code> values we want to match.  When one of the cells has a single defined value, we&#39;ll filter the possibilities of the other depending on whether the specified <code>Connection</code> is present.</p><pre><code class="language-haskell">connect :: a -&gt; a -&gt; BinaryR (OneOf (Combination a)) (OneOf (Combination a))
connect ex ey (x, y) = (x&#39;, y&#39;)
  where
    x&#39; = connect&#39; ex ey (x, y)
    y&#39; = connect&#39; ey ex (y, x)

    connect&#39; e1 e2 (c1, c2) = fromMaybe c1 $ do
      c &lt;- OneOf.only c2
      pure $
        if C.member e2 c
          then OneOf.filter (C.member e1) c1
          else OneOf.filter (C.notMember e1) c1
</code></pre><p>There might be a more elegant way of implementing this, but this gets the job done for us.  Now let&#39;s make our propagator network and put this to use.</p><pre><code class="language-haskell">-- the dimensions of the output &quot;image&quot;
height = 20
width = 80

generateTiles :: PropNetIO (Maybe [Tile])
generateTiles = do
  randomSeed
  cells &lt;- replicateM (height * width) empty

  -- no tiles with only one connection
  let validTiles = OneOf.filter (\x -&gt; C.size x /= 1) OneOf.universal
  traverse_ (`push` validTiles) cells

  let rows = chunksOf width cells
  let cols = transpose rows

  for_ (concat $ zipWith zip rows (drop 1 rows)) (enforceBinary (connect S N))
  for_ (concat $ zipWith zip cols (drop 1 cols)) (enforceBinary (connect E W))

  search cells
</code></pre><p><code>randomSeed</code> initializes the monad&#39;s internal RNG with system entropy.  The RNG determines the order in which branches are traversed during the search, so in networks with many valid solutions each run should produce a different result.</p><p>After creating our cells, we filter out combinations with only one connection (since our tileset doesn&#39;t include those).  Then we arrange the cells into rows and columns, and enforce our relation over each pair of adjacent cells both vertically and horizontally.</p><script src="https://asciinema.org/a/beztE6BGRI3DyQ46WtqN5eveT.js" id="asciicast-beztE6BGRI3DyQ46WtqN5eveT" async="true"></script>
<p>Wow it works!  Even though this is kind of a silly example, it&#39;s pretty fun to watch.  We can also restrict the subset of tiles that get used and generate a neat variety of patterns.</p><script src="https://asciinema.org/a/tm3xUBe1RsaTzr923YRplvoR6.js" id="asciicast-tm3xUBe1RsaTzr923YRplvoR6" async="true"></script>
<p>Anyway, that&#39;s about all I wanted to show off at this point.  The full source code for this example is also <a href="https://github.com/jehoz/propnet/blob/master/examples/Tiles.hs" title="">on Github</a>. If any of this seemed cool to you, you can download the library and play around with it yourself.  I&#39;ve tried to document everything inside the library source code, but feel free to get in touch and chastise me if anything doesn&#39;t make sense.</p>
        </div>
        <div id="spacer"></div>
        <div class="marquee">
            <div id="footer-inner">
                <span class="marquee-item">
                    <span>
                        thank you for reading
                    </span>
                    <img src="/static/img/templates/heart.gif"></img>
                </span>
                <span class="marquee-item">
                    <span>
                        please come back soon
                    </span>
                    <img src="/static/img/templates/wave.gif"></img>
                </span>
            </div>
            <script type="text/javascript">
                // duplicate the spans in the footer marquee 8 times
                let footer = document.getElementById("footer-inner");
                footer.innerHTML = footer.innerHTML.repeat(8);
            </script>
        </div>
    </div>
</body>

</html>
